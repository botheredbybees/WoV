ğŸ§ Nuyina Wildlife Observation System
ğŸ“¦ Version: 0.3.0
ğŸ“… Status: In Planning
ğŸŒ License: Creative Commons Attribution (CC BY 4.0) (recommend revisiting at launch)

ğŸš¢ Overview
This project documents the planning and development of a shipboard biodiversity logging platform for the RSV Nuyina.

The system is designed to support:

Casual expeditioner wildlife sightings (e.g., seabirds, whales, seals)

Structured ecological surveys (e.g., pelagic bird transects)

Integration with automated environmental context (via the InfluxDB-based underway data API)

Seamless and license-aware export to iNaturalist, ALA, and other biodiversity platforms

ğŸŒŸ Key Goals
ğŸ–¥ï¸ Cross-device web app for logging, reviewing, and exporting onboard wildlife observations.

ğŸ“¶ Offline-first operation with a fully local backend (Docker + Supabase + FastAPI).

ğŸ“¸ Image annotation and EXIF-based data linking for professional photo uploads.

ğŸ” Modular export support: ALA (Darwin Core), iNaturalist, eBird, BioCollect.

ğŸ—³ï¸ Group participation & engagement: voting, summaries, â€œphoto of the voyage.â€

ğŸ” Rich attribution + licensing metadata integrated at all levels.

ğŸ‘¥ Audience
Casual users (expeditioner photographers, general crew)

Scientific observers conducting structured protocols

Data management/admin teams

External data consumers: iNaturalist, ALA, AAD

ğŸ› ï¸ Technology Stack
Layer	Tool(s)
Frontend	SvelteKit / Vue 3 (touch & offline-friendly)
Backend	FastAPI (Python), Dockerized
Auth + Storage	Supabase (PostgreSQL, Auth, Storage + Studio)
Sensor Data	InfluxDB (underway data, containerized restore)
Image Viewer	HTML-based, zoomable image reference guide

Export to Sheets
ğŸ“ Repository Structure
```
/
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ data_design.md
â”‚   â”œâ”€â”€ data_dictionary.md
â”‚   â”œâ”€â”€ data_model_ERD.md
â”‚   â”œâ”€â”€ environment_setup_guide.md
â”‚   â”œâ”€â”€ EXIF_batcher.md
â”‚   â”œâ”€â”€ export-templates/
â”‚   â”‚   â”œâ”€â”€ iNaturalist_CSV_example.csv
â”‚   â”‚   â”œâ”€â”€ eBird_checklist_template.csv
â”‚   â”‚   â””â”€â”€ ALA_DarwinCore_template.csv
â”‚   â”œâ”€â”€ functional_design.md
â”‚   â”œâ”€â”€ project_brief.md
â”‚   â””â”€â”€ timeline.md
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ exif-batcher/
â”‚   â””â”€â”€ fastapi/
â”œâ”€â”€ supabase/
â”‚   â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ .branches/
â”‚   â””â”€â”€ .temp/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sql/
â””â”€â”€ .gitignore
```
Note: The supabase/ directory and its contents are managed automatically by the Supabase CLI and should not be modified manually.

ğŸ“¦ Getting Started
This guide assumes you are starting with a clean repository clone.

Clone the repository:

Bash

git clone https://github.com/botheredbybees/WoV.git
cd WoV
Install Prerequisites for Rocky Linux 8:

Docker Engine & Docker Compose: Follow the official Docker documentation for RHEL to install these.

Node.js & npm: Install via the NodeSource repository on RHEL.

Supabase CLI: Install as a dev dependency using npm.

Bash

npm i supabase --save-dev
Git: Install via sudo dnf install git.

Initialize and start Supabase services: This command will start all the necessary Docker containers for your local Supabase stack and apply your database schema defined in supabase/migrations/.

Bash

npx supabase db reset
Load Initial Data: Load the large SQL data files directly into the running PostgreSQL container using docker exec.

Bash

# First, verify your PostgreSQL container's name, it should be something like supabase_db_WoV
docker ps --filter "ancestor=public.ecr.aws/supabase/postgres" --format "{{.Names}}"

# Then, run the data load commands using the correct container name
docker exec -i <CONTAINER_NAME> psql -U postgres -d postgres < data/sql/01_wov_inaturalist_taxa.sql
docker exec -i <CONTAINER_NAME> psql -U postgres -d postgres < data/sql/02_wov_taxa.sql
docker exec -i <CONTAINER_NAME> psql -U postgres -d postgres < data/sql/03_wov_inaturalist_observations.sql
docker exec -i <CONTAINER_NAME> psql -U postgres -d postgres < data/sql/04_wov_dictionary.sql
docker exec -i <CONTAINER_NAME> psql -U postgres -d postgres < data/sql/05_seed_data.sql
Verify Setup: Check that Supabase Studio is accessible at http://localhost:54323 and that your tables and data are present in the wov schema.

ğŸ“„ Documentation Index
Project Brief

Functional Design

Data Design

Data Dictionary

Data Model (ERD)

EXIF Batcher Design

Environment Setup Guide

Project Timeline

ğŸ“¤ Export Templates â€” Coming soon

ğŸ¤ Contributions
Planning is collaborative! Feel free to open:

Ideas and enhancements

Structured export examples

Documentation PRs

ğŸ“ License & Attribution
Field observations and photos will be optionally released under researcher-chosen licenses (CC-BY / CC0 where possible). The platform's code will be MIT or similar.

Data sharing is designed to comply with ALA and iNaturalist rules around attribution, consent, and licensing.
